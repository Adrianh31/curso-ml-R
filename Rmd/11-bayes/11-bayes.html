<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Algoritmos Bayesianos para clasificación y regresión</title>
    <meta charset="utf-8" />
    <meta name="author" content="Víctor Gallego y Roi Naveiro" />
    <meta name="date" content="2019-05-25" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Algoritmos Bayesianos para clasificación y regresión
## Curso de aprendizaje automático para el INE
### Víctor Gallego y Roi Naveiro
### 2019-05-25

---


## Introducción


```r
a = rnorm(1000)
hist(a)
```

![](11-bayes_files/figure-html/unnamed-chunk-1-1.png)&lt;!-- --&gt;

---


class: middle, center, inverse

# Regresión Bayesiana

---

class: middle, center, inverse

# Clasificación Bayesiana

---

class: middle, center, inverse

# Inferencia Aproximada

---


## Repaso

* **Inferencia**: algunos de los nodos del modelo estarán fijados a ciertos valores conocidos (observados), y deseamos calcular la distribución posterior sobre (subconjuntos de) el resto de nodos (no observados).


* Caso más sencillo: supongamos que `\(p(x, y) = p(y|x)p(x)\)`, con el Teorema de Bayes

`\begin{equation}
p(x|y) = \frac{p(y|x)p(x)}{p(y)}
\end{equation}`

* Salvo en casos sencillos, la integral `\(p(y) = \int p(x,y) dx\)` es **intratable**.

--

* Introduciremos hoy dos familias de técnicas para **aproximar** el posterior:

  * **Basadas en muestreo**: Markov Chain Monte Carlo (MCMC).
  
  * **Basadas en optimización**: Inferencia Variacional (VI).

---

class: middle, center, inverse

# Markov Chain Monte Carlo

---

## Repaso de Monte Carlo

* El objetivo de los métodos Monte Carlo es el de calcular **esperanzas** con respecto a cierta distribución `\(p(z)\)`

`\begin{equation}
\mathbb{E} \left[ f(z) \right] = \int_{\mathcal{Z}} f(z)p(z)dz
\end{equation}`

* **Idea**: obtenemos una **muestra finita** `\(z^{(l)}, l=1,\ldots,L\)` de `\(p(z)\)`, por lo que podemos aproximar mediante

`\begin{equation}
\mathbb{E} \left[ f(z) \right] \approx \frac{1}{L} \sum_{l=1}^L f(z^{(l)})
\end{equation}`

* ¿Qué hacer cuando no podemos muestrear directamente de `\(p(z)\)`?

--

  * Muestreo por rechazo (**rejection sampling**): no es muy general.
  
  * Muestreo por importancia (**importance sampling**): solo para calcular integrales, no permite obtener muestras directamente: con lo que si queremos cambiar la `\(f(z)\)`, hay que repetir todo desde 0 (costoso).
  
  * **Markov Chain Monte Carlo (MCMC)**: general y obtiene muestras directamente.

---

## MCMC: fundamentos

* **Objetivo**: obtener muestras de `\(p(z)\)`.

* **Asumimos**: sabemos evaluar `\(p(z)\)` salvo constante de proporcionalidad.

  * Es decir, basta con saber evaluar `\(\tilde{p}(z) = Z p(z)\)`.
  
* **Idea**: generar muestras de una cadena de Markov cuya distribución invariante (límite) sea `\(p(z)\)`.

--

* **Esquema general**:

  1. A partir de la muestra actual `\(z^{(\tau)}\)`, generar una muestra *candidata* mediane una distribución (**proposal**),  `\(z^* \sim q(z | z^{(\tau)})\)`.
  
  2. Aceptamos la candidate mediante algún criterio.
  
  3. Si es aceptada, `\(z^{(\tau + 1)} = z^*\)`. Si no, `\(z^{(\tau + 1)} = z^{(\tau)}\)`, e iteramos.
  
  * Las muestras `\(z^{(1)}, z^{(2)}, \ldots\)` forman una cadena de Markov.

---

## Algoritmo de Metropolis

* El proposal tiene que ser simétrico: `\(q(z_A|z_B) = q(z_B | z_A)\)`.

* Aceptamos la muestra con probabilidad

`\begin{equation}
A(z^*, z^{(\tau)}) = \min (1, \frac{\tilde{p}(z^*)}{\tilde{p}(z^{(\tau)})})
\end{equation}`

--

* Típicamente, `\(q(z | z^{(\tau)}) \sim \mathcal{N}(z | z^{(\tau)}, \sigma)\)` (Random Walk Metropolis)

* Visualización interactiva en https://chi-feng.github.io/mcmc-demo/app.html#RandomWalkMH,banana.


---

## ¿Por qué funciona Metropolis?


---

### Algoritmo de Metropolis-Hastings

* Generalización que permite el uso de **cualquier proposal**.

* Ahora aceptaremos una muestra con probabilidad:

`\begin{equation}
A(z^*, z^{(\tau)}) = \min (1, \frac{\tilde{p}(z^*) q(z^{(\tau)} | z^*)  }{\tilde{p}(z^{(\tau)}) q(z^* | z^{(\tau)}) })
\end{equation}`

### Efecto de hiperparámetros

* Si el proposal es `\(q(z | z^{(\tau)}) \sim \mathcal{N}(z | z^{(\tau)}, \rho)\)`, valores **bajos** de `\(\rho\)` hacen que la tasa de aceptación sea alta, pero explore muy lentamente. Valores **altos** de `\(\rho\)` provocan que se explore más regiones del espacio, a costa de aumentar las muestras rechazadas.


&lt;center&gt;
![:scale 30%](./img/mcmc1.png)
&lt;/center&gt;



---

## Convergencia

* Rhat

* Muestra efectiva

* Disminuyendo correlaciones

---

## Gibbs sampling

* Caso especial de Metropolis-Hastings, utilizado cuando
  
  * El objetivo es multidimensional: `\(p(z) = p(z_1, \ldots, z_M)\)`.
  
  * Se conocen las marginales condicionadas `\(p(z_i | z_{\setminus i})\)`.


---

## Hamiltonian Monte Carlo (HMC)

* ¿Podemos mejorar el camino aleatorio de la cadena? 

* Además de aliviar el problema del tamaño del paso en Metropolis-Hastings.

--

* También conocido como Hybrid Monte Carlo, HMC es adecuado para espacios continuos:

  * Permite dar grandes saltos en el espacio.
  
  * Baja tasa de muestras rechazadas.
  
  * Necesita evaluar el gradiente de la logprobabilidad respecto a `\(z\)`.



---


class: middle, center, inverse

# Extra: breve intro a Stan

---

## Stan como PPL

* Lenguajes de **programación probabilística**.

* Separación entre **modelo** e **inferencia**.


---

## Flujo de trabajo con un PPL

1. Escribir el **modelo probabilístico** (priores + verosimilitudes).

2. Ejecutar el **motor de inferencia** (MCMC, VI, MAP, ...).

3. Diagnosticar la **convergencia**.

4. Realizar la **inferencia** (muestras del posterior).

---

## Modelos en Stan

* Se escriben en un mini-lenguaje (DSL) simple (no en R) para que posteriormente puedan ser compilados a C.

* Especificamos **parámetros** y **variables latentes**.

* Pantallazo de ejemplo:




---

## Motores de inferencia en Stan

* HMC/NUTS

&lt;center&gt;
![:scale 70%](./img/stan_nuts.png)
&lt;/center&gt;


* VI (**V**ariational **B**ayes, siguiente capítulo)

&lt;center&gt;
![:scale 60%](./img/stan_vb.png)
&lt;/center&gt;

---

## Diagnósticos en Stan

&lt;center&gt;
![:scale 100%](./img/stan_diag.png)
&lt;/center&gt;


* También visualizaciones:

  * plot(fit)
  
  * pairs(fit, pars = c("mu", "tau"))
  
  * traceplot(fit, pars = c("mu", "tau"), inc_warmup = TRUE, nrow = 2)


---

class: middle, center, inverse

# Inferencia Variacional

---
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="macros.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
