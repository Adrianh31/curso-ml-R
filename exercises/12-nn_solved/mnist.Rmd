---
title: "Redes Neuronales para clasificación de dígitos"
author: Victor Gallego y Roi Naveiro
date: "30/05/2019"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Cargamos los paquetes necesarios
```{r}
library(randomForest)
library(keras)
```


## Funciones auxiliares

* show_digit: Hace una gráfica del dígito en cuestión.
```{r, message=F}
show_digit = function(img){
  img = t( apply(img, 2, rev) )
  image( img )
}
```


## Lectura de Datos

Carga los datos de train y test en memoria

```{r}
mnist <- dataset_mnist()
x_train <- mnist$train$x
y_train <- mnist$train$y
x_test <- mnist$test$x
y_test <- mnist$test$y
```

Visualiza algún ejemplo

```{r}
y_train[6]
show_digit(x_train[6,,])
```

## Preprocesado de los datos

Antes del entrenamiento, es necesario aplanar los datos.

```{r}
# remodelado
dim(x_train) <- c(nrow(x_train), 784)
dim(x_test) <- c(nrow(x_test), 784)
```


También es necesario pasar las etiquetas a la notación OHE.

```{r}
y_train <- to_categorical(y_train, 10)
y_test <- to_categorical(y_test, 10)
```


## Definición y entrenamiento de un modelo de regresión logística regularizada

Define un modelo de regresión logística con 10 outputs.

```{r}
model_lr <- keras_model_sequential() 
model_lr %>% 
  layer_dense(units = 10, input_shape = c(784), activation = "softmax")
```

¿Cuántos parámetros entrenables tiene?, ¿por qué?

```{r}
summary(model_lr)
```

Definir la entropía cruzada como función de coste y rmsprop como optimizador.

```{r}
model_lr %>% compile(
  loss = "categorical_crossentropy",
  optimizer = optimizer_rmsprop(),
  metrics = c("accuracy")
)
```

Entrena el modelo con 30 épocas. Fija el tamaño de batch a 128. Además, escoge utiliza el 20% del conjunto de entrenamiento para la validación.

```{r}
history <- model_lr %>% fit(
  x_train, y_train, 
  epochs = 30, batch_size = 128, 
  validation_split = 0.2
)
```

Parece que se estanca y no aprende gran cosa... ¿Se te ocurreo alguna solución?

```{r}
# rescale
x_train <- x_train / 255
x_test <- x_test / 255
```

Una vez reescalamos...

```{r}
history <- model_lr %>% fit(
  x_train, y_train, 
  epochs = 30, batch_size = 128, 
  validation_split = 0.2
)
```

Veamos cómo mejorarlo con una red profunda.

## Definición y entrenamiento de la red Neuronal profunda

Definir una arquitectura de red que mapee el input a una capa densa con 256 unidades ocultas con activación tipo relu. La salida de estas capas ha de ser mapeada a otra capa densa con 128 unidades, también con activación relu. Finalmente, esta capa mandará señal a la capa final con 10 unidades y activación softmax para así recuperar probabilidades.

```{r}
model <- keras_model_sequential() 
model %>% 
  layer_dense(units = 256, activation = "relu", input_shape = c(784)) %>% 
  layer_dropout(rate = 0.4) %>% 
  layer_dense(units = 128, activation = "relu") %>%
  layer_dropout(rate = 0.3) %>%
  layer_dense(units = 10, activation = "softmax")
```

Resumen del modelo

```{r}
summary(model)
```
¿Cuál es el número total de parámetros entrenables en este caso?

Definir la entropía cruzada como función de coste y rmsprop como optimizador.

```{r}
model %>% compile(
  loss = "categorical_crossentropy",
  optimizer = optimizer_rmsprop(),
  metrics = c("accuracy")
)
```

Entrena el modelo durante 30 épocas

Entrena el modelo con 30 épocas. Fija el tamaño de batch a 128. Además, escoge utiliza el 20% del conjunto de entrenamiento para la validación.

```{r}
history <- model %>% fit(
  x_train, y_train, 
  epochs = 30, batch_size = 128, 
  validation_split = 0.2
)
```


## Evaluación y predicción en conjunto de test

¿Qué accuracy encuentras en el conjunto de test?

```{r}
model %>% evaluate(x_test, y_test,verbose = 0)
```


¿Detectas algún signo de overfitting?

## Guardar y leer modelos

Guarda el modelo creado en un fichero llamado "mnist_weights.hdf5". Lee el modelo de nuevo y realiza predicciones sobre el conjunto de test.

```{r}
save_model_hdf5(model, filepath = "mnist_weights.hdf5", overwrite = TRUE,
  include_optimizer = TRUE)

new_model = load_model_hdf5("mnist_weights.hdf5", custom_objects = NULL, compile = TRUE)
```


```{r}
new_model %>% predict_classes(x_test)
```
